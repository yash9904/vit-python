{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, RandomRotation, RandomAffine\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from vit import VIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = VIT(\n",
    "        shape=(1, 28, 28),\n",
    "        n_patches_w=7,\n",
    "        n_patches_h=7,\n",
    "        hidden_dim=48,\n",
    "        out_dim=10,\n",
    "        n_blocks=4,\n",
    "        n_heads=2,\n",
    "        encoder_mlp_ratio=4,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, n_epochs, batch_size):\n",
    "    writer = SummaryWriter('runs/vit_mnist_{}'.format(datetime.datetime.now(pytz.timezone('Asia/Kolkata')).strftime('%Y-%m-%d_%H-%M-%S')))\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    print(f\"CUDA available: {cuda_available}\")\n",
    "    if cuda_available:\n",
    "        model = model.cuda()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    total_train = len(train_data) \n",
    "    total_train = 10000 // batch_size\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for i, (x, y) in tqdm(\n",
    "            enumerate(train_data), total=total_train+1, desc=f\"Epoch {epoch}\"\n",
    "        ):\n",
    "            if i > total_train:\n",
    "                break\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x.cuda() if cuda_available else x)\n",
    "            loss = criterion(y_hat, y.cuda() if cuda_available else y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            writer.add_scalar(\"Loss/train\", loss, epoch * len(train_data) + i)\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in tqdm(val_data, desc=f\"Validation {epoch}\", total=len(val_data)):\n",
    "                if cuda_available:\n",
    "                    x, y = x.cuda(), y.cuda()\n",
    "                y_hat = model(x)\n",
    "                _, predicted = torch.max(y_hat.data, 1)\n",
    "                total += y.size(0)\n",
    "                correct += (predicted == y).sum().item()\n",
    "        accuracy = correct / total\n",
    "        writer.add_scalar(\"Accuracy/val\", accuracy, epoch)\n",
    "        print(f\"Epoch {epoch}, accuracy {accuracy}\")\n",
    "    writer.flush()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\vsc\\transformers_tutorial\\vit\\vit.py:177: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615347c59c3c47e0a321e4b1a1529ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce81baa7c61443eaccb423fe85d1060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation 0:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, accuracy 0.7793\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b407ae5a8e1498693dfd4f08306720a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2ee830692c4483850a296271952625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation 1:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, accuracy 0.8068\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1f2db4d3c64105bfc5a6fd04913079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4313e9af0f9e449d98747c4aec8533de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation 2:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, accuracy 0.8177\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de369916edb4de291876da7a00b9c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd473ee82f44d6aaf405ae429b19702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation 3:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, accuracy 0.8281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364598ab72c945949fec5c5279a13149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417c9be068fb407397079a52cd2ad75c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation 4:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, accuracy 0.8448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd4cf7a41044819bbee1ec261262f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbba495b29e459da7a27497ab0938c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation 5:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, accuracy 0.832\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d252ed93c468433291bb264f5d0f738b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m\n\u001b[0;32m      5\u001b[0m train_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[0;32m      6\u001b[0m     MNIST(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m\"\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform),\n\u001b[0;32m      7\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m      8\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m val_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[0;32m     11\u001b[0m     MNIST(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m\"\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform),\n\u001b[0;32m     12\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     13\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     14\u001b[0m )\n\u001b[1;32m---> 15\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_data, val_data, n_epochs, batch_size)\u001b[0m\n\u001b[0;32m     19\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m model(x\u001b[38;5;241m.\u001b[39mcuda() \u001b[38;5;28;01mif\u001b[39;00m cuda_available \u001b[38;5;28;01melse\u001b[39;00m x)\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_hat, y\u001b[38;5;241m.\u001b[39mcuda() \u001b[38;5;28;01mif\u001b[39;00m cuda_available \u001b[38;5;28;01melse\u001b[39;00m y)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     23\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss, epoch \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_data) \u001b[38;5;241m+\u001b[39m i)\n",
      "File \u001b[1;32md:\\Applicashuns\\mc3\\envs\\deep\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Applicashuns\\mc3\\envs\\deep\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 384\n",
    "n_epochs = 10\n",
    "\n",
    "transform = Compose([ToTensor(), RandomRotation(20), RandomAffine(10)])\n",
    "train_data = torch.utils.data.DataLoader(\n",
    "    MNIST(root=\"./data\", train=True, download=True, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_data = torch.utils.data.DataLoader(\n",
    "    MNIST(root=\"./data\", train=False, download=True, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "model = train(model, train_data, val_data, n_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 384\n",
    "n_epochs = 10\n",
    "\n",
    "transform = Compose([ToTensor(), RandomRotation(20), RandomAffine(10)])\n",
    "train_data = torch.utils.data.DataLoader(\n",
    "    MNIST(root=\"./data\", train=True, download=True, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([384, 1, 28, 28]) torch.Size([384])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_data:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx = 380\n",
    "plt.imshow(x[idx].squeeze(), cmap=\"gray\")\n",
    "plt.title(y[idx].item())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
